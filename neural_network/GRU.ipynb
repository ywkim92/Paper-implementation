{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.5em;\">[**reference**](https://wikidocs.net/22889)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "from scipy.stats import truncnorm, norm, levene, ttest_ind\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dense, LSTM, GRU, SimpleRNN, Bidirectional, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.initializers import GlorotNormal, GlorotUniform, Zeros\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.math import sigmoid, tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5533\n",
    "max_len = 20\n",
    "vocab_size = 1234\n",
    "embedding_dim = 300\n",
    "\n",
    "hidden_states = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: with embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "X = rng.integers(0,vocab_size, size=(n_samples, max_len))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length = max_len, ))\n",
    "X_emb = model(X)\n",
    "\n",
    "model.add(\n",
    "            GRU(hidden_states,  return_sequences=True, return_state=False, input_shape= (max_len, embedding_dim), reset_after=False, use_bias=True,\n",
    "               bias_initializer='glorot_normal')\n",
    "         )\n",
    "hidden_state = model(X)\n",
    "gru = model.layers[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if `reset_after=True`, then `bias` of GRUCell has (2, 3*`gru.units`) shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "ki = gru.cell.kernel[:, :hidden_states]\n",
    "kf = gru.cell.kernel[:, hidden_states:2*hidden_states]\n",
    "kc = gru.cell.kernel[:, 2*hidden_states:]\n",
    "\n",
    "\n",
    "ri = gru.cell.recurrent_kernel[:, :hidden_states]\n",
    "rf = gru.cell.recurrent_kernel[:, hidden_states:2*hidden_states]\n",
    "rc = gru.cell.recurrent_kernel[:, 2*hidden_states:]\n",
    "\n",
    "if gru.reset_after:\n",
    "    bi = gru.cell.bias[:, :hidden_states]\n",
    "    bf = gru.cell.bias[:, hidden_states:2*hidden_states]\n",
    "    bc = gru.cell.bias[:, 2*hidden_states:]\n",
    "else:\n",
    "    bi = gru.cell.bias[:hidden_states]\n",
    "    bf = gru.cell.bias[hidden_states:2*hidden_states]\n",
    "    bc = gru.cell.bias[2*hidden_states:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_emb_nor = tf.linalg.normalize(X_emb, axis=2, )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=00, validation - calculating hidden state: True 0.0\n",
      "t=01, validation - calculating hidden state: True 0.0\n",
      "t=02, validation - calculating hidden state: True 0.0\n",
      "t=03, validation - calculating hidden state: True 0.0\n",
      "t=04, validation - calculating hidden state: True 0.0\n",
      "t=05, validation - calculating hidden state: True 0.0\n",
      "t=06, validation - calculating hidden state: True 0.0\n",
      "t=07, validation - calculating hidden state: True 0.0\n",
      "t=08, validation - calculating hidden state: True 0.0\n",
      "t=09, validation - calculating hidden state: True 0.0\n",
      "t=10, validation - calculating hidden state: True 0.0\n",
      "t=11, validation - calculating hidden state: True 0.0\n",
      "t=12, validation - calculating hidden state: True 0.0\n",
      "t=13, validation - calculating hidden state: True 0.0\n",
      "t=14, validation - calculating hidden state: True 0.0\n",
      "t=15, validation - calculating hidden state: True 0.0\n",
      "t=16, validation - calculating hidden state: True 0.0\n",
      "t=17, validation - calculating hidden state: True 0.0\n",
      "t=18, validation - calculating hidden state: True 0.0\n",
      "t=19, validation - calculating hidden state: True 0.0\n"
     ]
    }
   ],
   "source": [
    "for t in range(max_len):\n",
    "    if t>0: htt = ht # hidden_state[:,t-1,:]\n",
    "    else: htt = tf.zeros((n_samples, hidden_states))\n",
    "    X_tf_ = X_emb[:,t,:]\n",
    "    \n",
    "    if gru.reset_after:\n",
    "        zt = gru.recurrent_activation(K.bias_add(tf.matmul(X_tf_, ki), bi[0]) + K.bias_add(tf.matmul(htt, ri), bi[1]))\n",
    "        rt = gru.recurrent_activation(K.bias_add(tf.matmul(X_tf_, kf), bf[0]) + K.bias_add(tf.matmul(htt, rf), bf[1]))\n",
    "\n",
    "        gt = gru.activation(K.bias_add(tf.matmul(X_tf_, kc), bc[0]) + rt*(K.bias_add(tf.matmul(htt, rc), bc[1])) )\n",
    "    else:\n",
    "        zt = gru.recurrent_activation(K.bias_add(tf.matmul(X_tf_, ki), bi) + (tf.matmul(htt, ri)) )\n",
    "        rt = gru.recurrent_activation(K.bias_add(tf.matmul(X_tf_, kf), bf) + (tf.matmul(htt, rf)) )\n",
    "\n",
    "        gt = gru.activation(K.bias_add(tf.matmul(X_tf_, kc), bc) + (tf.matmul(rt*htt, rc)) )\n",
    "    ht = (1-zt)*gt + zt*htt\n",
    "    \n",
    "    print('t={}'.format(str(t).zfill(2)), end=', ')\n",
    "    print('validation - calculating hidden state:', np.alltrue(hidden_state[:,t,:]== ht, ), abs(ht- hidden_state[:,t,:]).numpy().max() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: with normalizing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "X = rng.normal(size=(n_samples, max_len, embedding_dim))\n",
    "# X_tf = tf.linalg.normalize(X, axis=2, )[0]\n",
    "# X = np.array([Normalizer().fit_transform(X[s]) for s in range(n_samples) ])\n",
    "X_tf = tf.cast(X, dtype=tf.float32)\n",
    "\n",
    "gru = GRU(hidden_states,  return_sequences=True, return_state=True, input_shape= (max_len, embedding_dim), reset_after=False,\n",
    "         bias_initializer='uniform')\n",
    "hidden_state, last_state, = gru(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5533, 20, 128])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.alltrue(hidden_state[:,-1,:]==last_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(X.flatten(), bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "ki = gru.cell.kernel[:, :hidden_states]\n",
    "kf = gru.cell.kernel[:, hidden_states:2*hidden_states]\n",
    "kc = gru.cell.kernel[:, 2*hidden_states:]\n",
    "\n",
    "\n",
    "ri = gru.cell.recurrent_kernel[:, :hidden_states]\n",
    "rf = gru.cell.recurrent_kernel[:, hidden_states:2*hidden_states]\n",
    "rc = gru.cell.recurrent_kernel[:, 2*hidden_states:]\n",
    "\n",
    "if gru.reset_after:\n",
    "    bi = gru.cell.bias[:, :hidden_states]\n",
    "    bf = gru.cell.bias[:, hidden_states:2*hidden_states]\n",
    "    bc = gru.cell.bias[:, 2*hidden_states:]\n",
    "else:\n",
    "    bi = gru.cell.bias[:hidden_states]\n",
    "    bf = gru.cell.bias[hidden_states:2*hidden_states]\n",
    "    bc = gru.cell.bias[2*hidden_states:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=00, validation - calculating hidden state: True 0.0\n",
      "t=01, validation - calculating hidden state: True 0.0\n",
      "t=02, validation - calculating hidden state: True 0.0\n",
      "t=03, validation - calculating hidden state: True 0.0\n",
      "t=04, validation - calculating hidden state: True 0.0\n",
      "t=05, validation - calculating hidden state: True 0.0\n",
      "t=06, validation - calculating hidden state: True 0.0\n",
      "t=07, validation - calculating hidden state: True 0.0\n",
      "t=08, validation - calculating hidden state: True 0.0\n",
      "t=09, validation - calculating hidden state: True 0.0\n",
      "t=10, validation - calculating hidden state: True 0.0\n",
      "t=11, validation - calculating hidden state: True 0.0\n",
      "t=12, validation - calculating hidden state: True 0.0\n",
      "t=13, validation - calculating hidden state: True 0.0\n",
      "t=14, validation - calculating hidden state: True 0.0\n",
      "t=15, validation - calculating hidden state: True 0.0\n",
      "t=16, validation - calculating hidden state: True 0.0\n",
      "t=17, validation - calculating hidden state: True 0.0\n",
      "t=18, validation - calculating hidden state: True 0.0\n",
      "t=19, validation - calculating hidden state: True 0.0\n"
     ]
    }
   ],
   "source": [
    "for t in range(max_len):\n",
    "    if t>0: htt = ht # hidden_state[:,t-1,:]\n",
    "    else: htt = tf.zeros((n_samples, hidden_states))\n",
    "    X_tf_ = X_tf[:,t,:]\n",
    "\n",
    "    if gru.reset_after:\n",
    "        zt = gru.recurrent_activation(K.bias_add(tf.matmul(X_tf_, ki), bi[0]) + K.bias_add(tf.matmul(htt, ri), bi[1]))\n",
    "        rt = gru.recurrent_activation(K.bias_add(tf.matmul(X_tf_, kf), bf[0]) + K.bias_add(tf.matmul(htt, rf), bf[1]))\n",
    "\n",
    "        gt = gru.activation(K.bias_add(tf.matmul(X_tf_, kc), bc[0]) + rt*(K.bias_add(tf.matmul(htt, rc), bc[1])) )\n",
    "    else:\n",
    "        zt = gru.recurrent_activation(K.bias_add(tf.matmul(X_tf_, ki), bi) + (tf.matmul(htt, ri)) )\n",
    "        rt = gru.recurrent_activation(K.bias_add(tf.matmul(X_tf_, kf), bf) + (tf.matmul(htt, rf)) )\n",
    "\n",
    "        gt = gru.activation(K.bias_add(tf.matmul(X_tf_, kc), bc) + (tf.matmul(rt*htt, rc)) )\n",
    "    ht = (1-zt)*gt + zt*htt\n",
    "    \n",
    "    print('t={}'.format(str(t).zfill(2)), end=', ')\n",
    "    print('validation - calculating hidden state:', np.alltrue(hidden_state[:,t,:] == ht, ), abs(ht- hidden_state[:,t,:]).numpy().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
