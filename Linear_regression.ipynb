{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import t, f, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.feature_selection import RFE, RFECV, SelectFromModel, SequentialFeatureSelector\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_regression:\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_ = np.append(np.ones((X.shape[0], 1)), X, axis=1)\n",
    "        Q = np.linalg.inv(X_.T.dot(X_))\n",
    "        self.beta = Q.dot(X_.T).dot(y)\n",
    "        \n",
    "        n = X.shape[0]\n",
    "        p = X.shape[1]\n",
    "        self.n_samples = n\n",
    "        self.n_features = p\n",
    "        y_hat = X_.dot(self.beta)\n",
    "        \n",
    "        self.residual = y - y_hat\n",
    "        sse = np.square(self.residual).sum()\n",
    "        ssr = np.square(y_hat - y.mean()).sum()\n",
    "        sst = np.square(y - y.mean()).sum()\n",
    "        self.mse = sse/(n-p-1)\n",
    "        \n",
    "        self.r_sq = 1 - sse/sst\n",
    "        self.adj_r = 1 - (sse/(n-p-1))/(sst/(n-1))\n",
    "        \n",
    "        self.f_value = (ssr/p) / (sse/(n-p-1))\n",
    "        self.f_pvalue = 1 - f.cdf(self.f_value, dfn = p, dfd = n - p - 1)\n",
    "        \n",
    "        self.std_error = np.sqrt((sse/(n-p-1)) * Q.diagonal())\n",
    "        self.t_values = self.beta / self.std_error\n",
    "        self.t_pvalues = [2*(1 - t.cdf(abs(i), n-p-1)) for i in self.t_values]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X_ = np.append(np.ones((X.shape[0], 1)), X, axis=1)\n",
    "        return X_.dot(self.beta)\n",
    "    \n",
    "    def summary(self, feature_names = None, round_decimals=3, alpha=0.05):\n",
    "        res_min = self.residual.min()\n",
    "        res_max = self.residual.max()\n",
    "        res_1q = np.quantile(self.residual, .25)\n",
    "        res_med = np.median(self.residual)\n",
    "        res_3q = np.quantile(self.residual, .75)\n",
    "        res = pd.DataFrame(np.array([res_min, res_1q, res_med, res_3q, res_max]).reshape(1,-1), columns = ['Residuals: Min', '1Q', 'Median', '3Q', 'Max'])\n",
    "        \n",
    "        ci_lower = np.round(self.beta - self.std_error * t.ppf(1-alpha/2, self.n_samples - self.n_features -1), round_decimals)\n",
    "        ci_upper = np.round(self.beta + self.std_error * t.ppf(1-alpha/2, self.n_samples - self.n_features -1), round_decimals)\n",
    "        if feature_names is None:\n",
    "            feat_idx = ['x0(INTCP)'] + ['x{}'.format(i) for i in range(1, n_features+1)]\n",
    "            coef = pd.DataFrame(np.array([self.beta, self.std_error, self.t_values, np.round(self.t_pvalues, round_decimals), ci_lower, ci_upper]).T, index = feat_idx, columns= \n",
    "                               ['coef.', 'std. error', 't_value', 'Pr(>|t|)', '{}% LWR'.format(int(100*(1-alpha))), '{}% UPR'.format(int(100*(1-alpha)))])\n",
    "        else:\n",
    "            feat_idx = np.insert(feature_names, 0, '(INTCP)')\n",
    "            coef = pd.DataFrame(np.array([self.beta, self.std_error, self.t_values, np.round(self.t_pvalues, round_decimals), ci_lower, ci_upper]).T, index = feat_idx, columns= \n",
    "                               ['coef.', 'std. error', 't_value', 'Pr(>|t|)', '{}% LWR'.format(int(100*(1-alpha))), '{}% UPR'.format(int(100*(1-alpha)))])\n",
    "        \n",
    "        r2 = 'R-squared: {}, Adjusted R-squared: {}'.format(self.r_sq, self.adj_r)\n",
    "        res_std_err = 'Residual standard error: {} on {} degrees of freedom'.format(self.mse, self.n_samples - self.n_features -1)\n",
    "        F_stats = 'F-statistic: {} on {} and {} DF, p-value: {}'.format(self.f_value, self.n_features, self.n_samples - self.n_features -1, self.f_pvalue)\n",
    "        print(res, coef, res_std_err, r2, F_stats, sep='\\n'+'='*70+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, feature_names, _, _ = load_boston().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(X, columns = feature_names), pd.Series(y, name='label'), test_size = .2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_regression()\n",
    "lr.fit(X_train, y_train)\n",
    "pred_ = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.09349529811247"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.093495298112458"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(pred,pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Residuals: Min        1Q    Median        3Q        Max\n",
      "0      -13.392716 -2.713732 -0.537744  1.537035  24.893577\n",
      "======================================================================\n",
      "             coef.  std. error    t_value  Pr(>|t|)  95% LWR  95% UPR\n",
      "(INTCP)  22.522277    0.236767  95.124364     0.000   22.057   22.988\n",
      "CRIM     -1.026701    0.312280  -3.287755     0.001   -1.641   -0.413\n",
      "ZN        1.350413    0.375499   3.596319     0.000    0.612    2.089\n",
      "INDUS     0.125577    0.462665   0.271420     0.786   -0.784    1.035\n",
      "CHAS      0.575228    0.245493   2.343150     0.020    0.093    1.058\n",
      "NOX      -2.286092    0.499211  -4.579411     0.000   -3.268   -1.305\n",
      "RM        2.130839    0.329607   6.464787     0.000    1.483    2.779\n",
      "AGE       0.127024    0.425805   0.298316     0.766   -0.710    0.964\n",
      "DIS      -3.178567    0.485752  -6.543602     0.000   -4.134   -2.224\n",
      "RAD       2.647306    0.675885   3.916797     0.000    1.318    3.976\n",
      "TAX      -1.877813    0.741576  -2.532191     0.012   -3.336   -0.420\n",
      "PTRATIO  -2.142964    0.323162  -6.631241     0.000   -2.778   -1.508\n",
      "B         0.669374    0.275721   2.427723     0.016    0.127    1.211\n",
      "LSTAT    -3.925510    0.413679  -9.489273     0.000   -4.739   -3.112\n",
      "======================================================================\n",
      "Residual standard error: 22.647612986695794 on 390 degrees of freedom\n",
      "======================================================================\n",
      "R-squared: 0.7293585058196337, Adjusted R-squared: 0.7203371226802882\n",
      "======================================================================\n",
      "F-statistic: 80.84774746331682 on 13 and 390 DF, p-value: 1.1102230246251565e-16\n"
     ]
    }
   ],
   "source": [
    "lr = linear_regression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.summary(feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  label   R-squared:                       0.729\n",
      "Model:                            OLS   Adj. R-squared:                  0.720\n",
      "Method:                 Least Squares   F-statistic:                     80.85\n",
      "Date:                Sun, 01 Aug 2021   Prob (F-statistic):          5.53e-102\n",
      "Time:                        00:36:15   Log-Likelihood:                -1196.4\n",
      "No. Observations:                 404   AIC:                             2421.\n",
      "Df Residuals:                     390   BIC:                             2477.\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         22.5223      0.237     95.124      0.000      22.057      22.988\n",
      "x1            -1.0267      0.312     -3.288      0.001      -1.641      -0.413\n",
      "x2             1.3504      0.375      3.596      0.000       0.612       2.089\n",
      "x3             0.1256      0.463      0.271      0.786      -0.784       1.035\n",
      "x4             0.5752      0.245      2.343      0.020       0.093       1.058\n",
      "x5            -2.2861      0.499     -4.579      0.000      -3.268      -1.305\n",
      "x6             2.1308      0.330      6.465      0.000       1.483       2.779\n",
      "x7             0.1270      0.426      0.298      0.766      -0.710       0.964\n",
      "x8            -3.1786      0.486     -6.544      0.000      -4.134      -2.224\n",
      "x9             2.6473      0.676      3.917      0.000       1.318       3.976\n",
      "x10           -1.8778      0.742     -2.532      0.012      -3.336      -0.420\n",
      "x11           -2.1430      0.323     -6.631      0.000      -2.778      -1.508\n",
      "x12            0.6694      0.276      2.428      0.016       0.127       1.211\n",
      "x13           -3.9255      0.414     -9.489      0.000      -4.739      -3.112\n",
      "==============================================================================\n",
      "Omnibus:                      162.425   Durbin-Watson:                   1.892\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              785.316\n",
      "Skew:                           1.688   Prob(JB):                    2.96e-171\n",
      "Kurtosis:                       8.937   Cond. No.                         10.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "X2 = sm.add_constant(X_train)\n",
    "est = sm.OLS(y_train, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
