{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import t, f, norm\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\displaystyle \\Large \\mathcal{L}(\\mathbf{X},\\mathbf{y}|\\mathbf{\\beta}) = \\prod_{i=1}^{n} \\sigma(\\mathbf{y}\\circ\\mathbf{X}\\mathbf{\\beta})=\\prod_{i=1}^{n}\\frac{1}{1+e^{\\mathbf{y}\\circ\\mathbf{X}\\mathbf{\\beta}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression:\n",
    "    def __init__(self, solver = 'lbfgs', penalty = 'l2', C = 1., tol = 1e-8, max_iter=100):\n",
    "        self.solver = solver\n",
    "        self.penalty = penalty\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def _sigmoid(self, beta, data):\n",
    "        return 1/(1+np.exp(-data.dot(beta)))\n",
    "    \n",
    "    def _llf_none(self, beta, data, label, return_array=False):\n",
    "        target = np.array([-1 if i ==0 else 1 for i in label.values])\n",
    "        value = sum( np.log( 1/( 1+np.exp(-(target*(data.dot(beta)))) ) ) )\n",
    "        if return_array: return -value, np.log( 1/( 1+np.exp(-(target*(data.dot(beta)))) ) )\n",
    "        else: return -value\n",
    "    \n",
    "    def _llf_l2(self, beta, data, label, ):\n",
    "        target = np.array([-1 if i ==0 else 1 for i in label.values])\n",
    "        value = sum( np.log( 1/( 1+np.exp(-(target*(data.dot(beta)))) ) ) )\n",
    "        return -(self.C * value) + beta.dot(beta)/2\n",
    "\n",
    "    # Iteratively reweighted least square\n",
    "    def _irls(self, data, label, w_init, penalty, C, cnvg_tol, max_iter):\n",
    "        # data with intercept\n",
    "        x = data.copy()\n",
    "        \n",
    "        # coefs with bias\n",
    "        w = w_init.copy()\n",
    "        mu = 1/(1+np.exp(-x.dot(w)))\n",
    "\n",
    "        s = np.zeros((data.shape[0], data.shape[0]))\n",
    "        np.fill_diagonal(s, [i*(1-i) for i in mu])\n",
    "        cost = 0\n",
    "\n",
    "        for n_iter in range(max_iter):\n",
    "            w_0 = w\n",
    "            w = np.linalg.inv( (x.T).dot(s.dot(x)) ).dot(x.T).dot( s.dot(x.dot(w)) + label.values - mu )\n",
    "            if penalty == 'none':\n",
    "                c = self._llf_none(w, x, label)\n",
    "            elif penalty == 'l2':\n",
    "                c = self._llf_l2(w, x, label)\n",
    "            else:\n",
    "                raise ValueError(\"This penalty is not supported yet.\") from None\n",
    "\n",
    "            if n_iter==0:\n",
    "                cost = c\n",
    "                mu = 1/(1+np.exp(-x.dot(w)))\n",
    "                np.fill_diagonal(s, [i*(1-i) for i in mu])\n",
    "            else:\n",
    "                if (c > cost)|(c!=c)|((cost - c) < cnvg_tol):\n",
    "                    w = w_0\n",
    "                    break\n",
    "                else:\n",
    "                    cost = c\n",
    "                    mu = 1/(1+np.exp(-x.dot(w)))\n",
    "                    np.fill_diagonal(s, [i*(1-i) for i in mu])\n",
    "            \n",
    "        return w, n_iter\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_ = np.append(np.ones((X.shape[0], 1)), X, axis=1)\n",
    "        \n",
    "        # initialize bias\n",
    "        b0_init = np.log(y.mean()/(1- y.mean()))\n",
    "        self.coef_ = np.array([b0_init]+[.0]*(X.shape[1]))\n",
    "        \n",
    "        if self.solver == 'lbfgs':\n",
    "            if self.penalty == 'l2':\n",
    "                coef =  minimize(self._llf_l2, x0 = self.coef_, args = (X_, y), method = 'L-BFGS-B', )['x'] #options={'gtol': 1e-3, 'disp': True}\n",
    "                self.coef_ = coef.copy()\n",
    "                self.log_likelihood = -self._llf_l2(coef, X_, y)\n",
    "            elif self.penalty == 'none':\n",
    "                coef =  minimize(self._llf_none, x0 = self.coef_, args = (X_, y), method = 'L-BFGS-B', )['x']\n",
    "                self.coef_ = coef.copy()\n",
    "                self.log_likelihood = -self._llf_none(coef, X_, y)\n",
    "            else:\n",
    "                raise ValueError(\"Solver lbfgs supports only 'l2' or 'none' penalties\") from None\n",
    "        elif self.solver == 'irls':\n",
    "            coef, self.n_iter = self._irls(X_, y, self.coef_, self.penalty, self.C, self.tol, self.max_iter)\n",
    "            self.coef_ = coef.copy()\n",
    "            if self.penalty=='l2':\n",
    "                self.log_likelihood = -self._llf_l2(coef, X_, y)\n",
    "            else:\n",
    "                self.log_likelihood = -self._llf_none(coef, X_, y)\n",
    "        else:\n",
    "            raise ValueError(\"This solver is not supported.\") from None\n",
    "        \n",
    "        n = X.shape[0]\n",
    "        p = X.shape[1]\n",
    "        self.n_samples = n\n",
    "        self.n_features = p\n",
    "        \n",
    "        mu = self._sigmoid(self.coef_, X_)\n",
    "        if self.solver=='irls':\n",
    "            self.deviance = -2*self.log_likelihood #-2*( ((X_.dot(self.coef_)).T).dot(y) + np.log(1 - mu).sum() )\n",
    "#             self.residual_deviance = np.sqrt( -2*( (X_.dot(self.coef_))*(y) + np.log(1 - mu) ) )* np.sign(y - mu)\n",
    "        self.residual_pearson = (y - mu)/np.sqrt(mu*(1-mu))\n",
    "        self.pearson_chi2 = np.square(self.residual_pearson).sum()\n",
    "        \n",
    "        S = np.zeros((X_.shape[0], X_.shape[0]))\n",
    "        np.fill_diagonal(S, [i*(1-i) for i in mu])\n",
    "        covar = np.linalg.inv((X_.T).dot(S.dot(X_)))\n",
    "        \n",
    "        self.std_error = np.sqrt(np.diag( covar ))\n",
    "        self.z_values = self.coef_ / self.std_error\n",
    "        self.z_pvalues = [2*(1 - norm.cdf(abs(i),)) for i in self.z_values]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_ = np.append(np.ones((X.shape[0], 1)), X, axis=1)\n",
    "        result = np.array([1 if i >= .5 else 0 for i in self._sigmoid(self.coef_, X_)])\n",
    "        return result\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X_ = np.append(np.ones((X.shape[0], 1)), X, axis=1)\n",
    "        result = np.vstack((1. - self._sigmoid(self.coef_, X_), self._sigmoid(self.coef_, X_)))\n",
    "        return result.T\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X,)\n",
    "        return np.array(pred==y, dtype=int).sum() / y.size\n",
    "    \n",
    "    def summary(self, feature_names = None, round_decimals=3, alpha=0.05):\n",
    "        '''res_min = self.residual.min()\n",
    "        res_max = self.residual.max()\n",
    "        res_1q = np.quantile(self.residual, .25)\n",
    "        res_med = np.median(self.residual)\n",
    "        res_3q = np.quantile(self.residual, .75)\n",
    "        res = pd.DataFrame(np.array([res_min, res_1q, res_med, res_3q, res_max]).reshape(1,-1), columns = ['Residuals: Min', '1Q', 'Median', '3Q', 'Max'])'''\n",
    "        \n",
    "        ci_lower = np.round(self.coef_ - self.std_error * norm.ppf(1-alpha/2, ), round_decimals)\n",
    "        ci_upper = np.round(self.coef_ + self.std_error * norm.ppf(1-alpha/2, ), round_decimals)\n",
    "        if feature_names is None:\n",
    "            feat_idx = ['x0(INTCP)'] + ['x{}'.format(i) for i in range(1, self.n_features+1)]\n",
    "            coef = pd.DataFrame(np.array([self.coef_, self.std_error, self.z_values, np.round(self.z_pvalues, round_decimals), ci_lower, ci_upper]).T, index = feat_idx, columns= \n",
    "                               ['coef.', 'std. error', 'z_value', 'Pr(>|z|)', '{}% LWR'.format(int(100*(1-alpha))), '{}% UPR'.format(int(100*(1-alpha)))])\n",
    "        else:\n",
    "            feat_idx = np.insert(feature_names, 0, '(INTCP)')\n",
    "            coef = pd.DataFrame(np.array([self.coef_, self.std_error, self.z_values, np.round(self.z_pvalues, round_decimals), ci_lower, ci_upper]).T, index = feat_idx, columns= \n",
    "                               ['coef.', 'std. error', 'z_value', 'Pr(>|z|)', '{}% LWR'.format(int(100*(1-alpha))), '{}% UPR'.format(int(100*(1-alpha)))])\n",
    "        \n",
    "        if self.solver == 'irls':\n",
    "            result = 'No. Observations: {}\\nDF Residuals: {}\\nLog-likelihood: {}\\nDeviance: {}\\nPearson chi2: {}'.format(self.n_samples, self.n_features, self.log_likelihood, self.deviance, self.pearson_chi2)\n",
    "            sol = 'Solver: {}\\nNo. Iterations: {}'.format(self.solver.upper(), self.n_iter)\n",
    "            print(sol, result, coef, sep='\\n'+'='*70+'\\n')\n",
    "        else:\n",
    "            result = 'No. Observations: {}\\nDF Residuals: {}\\nLog-likelihood: {}\\nPearson chi2: {}'.format(self.n_samples, self.n_features, self.log_likelihood, self.pearson_chi2)\n",
    "            print(result, coef, sep='\\n'+'='*70+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y, feature_names,  = data['data'], 1 - data['target'], data['feature_names']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(X, columns = feature_names), pd.Series(y, name='label'), test_size = .2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, index = y_train.index, columns = feature_names)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, index = y_test.index, columns = feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation for the result of my implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver: irls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  label   No. Observations:                  455\n",
      "Model:                            GLM   Df Residuals:                      448\n",
      "Model Family:                Binomial   Df Model:                            6\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -89.286\n",
      "Date:                Mon, 30 Aug 2021   Deviance:                       178.57\n",
      "Time:                        21:12:38   Pearson chi2:                 1.48e+03\n",
      "No. Iterations:                     7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.2369      0.216     -5.728      0.000      -1.660      -0.814\n",
      "x1             0.2696      0.288      0.935      0.350      -0.296       0.835\n",
      "x2             0.2354      0.561      0.420      0.675      -0.864       1.335\n",
      "x3             0.2167      0.495      0.438      0.662      -0.754       1.187\n",
      "x4             4.4891      0.625      7.178      0.000       3.263       5.715\n",
      "x5             0.7051      0.281      2.511      0.012       0.155       1.255\n",
      "x6            -1.5538      0.443     -3.510      0.000      -2.422      -0.686\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "Xs = sm.add_constant(X_train[:, -6:])\n",
    "logit = sm.GLM(y_train, Xs, family=sm.families.Binomial(), )\n",
    "result = logit.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: IRLS\n",
      "No. Iterations: 7\n",
      "======================================================================\n",
      "No. Observations: 455\n",
      "DF Residuals: 6\n",
      "Log-likelihood: -89.2857387331258\n",
      "Deviance: 178.5714774662516\n",
      "Pearson chi2: 1484.4789667633581\n",
      "======================================================================\n",
      "              coef.  std. error   z_value  Pr(>|z|)  95% LWR  95% UPR\n",
      "x0(INTCP) -1.236908    0.215952 -5.727696     0.000   -1.660   -0.814\n",
      "x1         0.269614    0.288392  0.934889     0.350   -0.296    0.835\n",
      "x2         0.235429    0.561026  0.419640     0.675   -0.864    1.335\n",
      "x3         0.216709    0.495205  0.437615     0.662   -0.754    1.187\n",
      "x4         4.489082    0.625409  7.177829     0.000    3.263    5.715\n",
      "x5         0.705100    0.280765  2.511349     0.012    0.155    1.255\n",
      "x6        -1.553841    0.442719 -3.509767     0.000   -2.422   -0.686\n"
     ]
    }
   ],
   "source": [
    "lr = logistic_regression(solver = 'irls', penalty='none', C=1.)\n",
    "lr.fit(X_train[:, -6:], y_train)\n",
    "\n",
    "lr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver: l-bfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: accuracy 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000, penalty='l2', )\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict_proba(X_test)[:, 1]\n",
    "print('sklearn: accuracy',model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: accuracy 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "lr_lb = logistic_regression(solver = 'lbfgs', penalty='l2', C=1.)\n",
    "lr_lb.fit(X_train, y_train)\n",
    "pred_ = lr_lb.predict_proba(X_test)[:, 1]\n",
    "print('sklearn: accuracy', lr_lb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef. sklearn == my implementation?: False\n"
     ]
    }
   ],
   "source": [
    "print('coef. sklearn == my implementation?:', np.allclose(np.append(model.intercept_, model.coef_.flatten()), lr_lb.coef_) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MAE for predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009100549773208128"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(pred - pred_).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,20))\n",
    "plt.boxplot((pred - pred_), )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
