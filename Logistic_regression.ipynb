{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import t, f, norm\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression:\n",
    "    def __init__(self, solver = 'lbfgs', penalty = 'l2', C = 1., tol = 1e-8, max_iter=100):\n",
    "        self.solver = solver\n",
    "        self.penalty = penalty\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def _sigmoid(self, beta, data):\n",
    "        return 1/(1+np.exp(-data.dot(beta)))\n",
    "    \n",
    "    def _llf_none(self, beta, data, label, ):\n",
    "        target = np.array([-1 if i ==0 else 1 for i in label.values])\n",
    "        value = sum( np.log( 1/( 1+np.exp(-(target*(data.dot(beta)))) ) ) )\n",
    "        return -value\n",
    "    \n",
    "    def _llf_l2(self, beta, data, label, ):\n",
    "        target = np.array([-1 if i ==0 else 1 for i in label.values])\n",
    "        value = sum( np.log( 1/( 1+np.exp(-(target*(data.dot(beta)))) ) ) )\n",
    "        return -(self.C * value) + beta.dot(beta)/2\n",
    "\n",
    "    def _irls(self, data, label, w_init, penalty, C, cnvg_tol, max_iter):\n",
    "        x = data.copy()\n",
    "        w = w_init.copy()\n",
    "        mu = 1/(1+np.exp(-x.dot(w)))\n",
    "\n",
    "        s = np.zeros((data.shape[0], data.shape[0]))\n",
    "        np.fill_diagonal(s, [i*(1-i) for i in mu])\n",
    "        cost = 0\n",
    "\n",
    "        for n_iter in range(max_iter):\n",
    "            w_0 = w\n",
    "            w = np.linalg.inv( (x.T).dot(s.dot(x)) ).dot(x.T).dot( s.dot(x.dot(w)) + label.values - mu )\n",
    "            if penalty == 'none':\n",
    "                c = self._llf_none(w, x, label)\n",
    "            elif penalty == 'l2':\n",
    "                c = self._llf_l2(w, x, label)\n",
    "            else:\n",
    "                raise ValueError(\"This penalty is not supported yet.\") from None\n",
    "\n",
    "            if n_iter==0:\n",
    "                cost = c\n",
    "                mu = 1/(1+np.exp(-x.dot(w)))\n",
    "                np.fill_diagonal(s, [i*(1-i) for i in mu])\n",
    "            else:\n",
    "                if (c > cost)|(c!=c)|((cost - c) < cnvg_tol):\n",
    "                    w = w_0\n",
    "                    break\n",
    "                else:\n",
    "                    cost = c\n",
    "                    mu = 1/(1+np.exp(-x.dot(w)))\n",
    "                    np.fill_diagonal(s, [i*(1-i) for i in mu])\n",
    "            \n",
    "        return w, n_iter\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_ = np.append(np.ones((X.shape[0], 1)), X, axis=1)\n",
    "        \n",
    "        b0_init = np.log(y.mean()/(1- y.mean()))\n",
    "        self.coef_ = np.array([b0_init]+[.0]*(X.shape[1]))\n",
    "        \n",
    "        if self.solver == 'lbfgs':\n",
    "            if self.penalty == 'l2':\n",
    "                coef =  minimize(self._llf_l2, x0 = self.coef_, args = (X_, y), method = 'L-BFGS-B', )['x'] #options={'gtol': 1e-3, 'disp': True}\n",
    "                self.coef_ = coef.copy()\n",
    "                self.log_likelihood = -self._llf_l2(coef, X_, y)\n",
    "            elif self.penalty == 'none':\n",
    "                coef =  minimize(self._llf_none, x0 = self.coef_, args = (X_, y), method = 'L-BFGS-B', )['x']\n",
    "                self.coef_ = coef.copy()\n",
    "                self.log_likelihood = -self._llf_none(coef, X_, y)\n",
    "            else:\n",
    "                raise ValueError(\"Solver lbfgs supports only 'l2' or 'none' penalties\") from None\n",
    "        elif self.solver == 'irls':\n",
    "            coef, self.n_iter = self._irls(X_, y, self.coef_, self.penalty, self.C, self.tol, self.max_iter)\n",
    "            self.coef_ = coef.copy()\n",
    "            if self.penalty=='l2':\n",
    "                self.log_likelihood = -self._llf_l2(coef, X_, y)\n",
    "            else:\n",
    "                self.log_likelihood = -self._llf_none(coef, X_, y)\n",
    "        else:\n",
    "            raise ValueError(\"This Solver is not supported.\") from None\n",
    "        \n",
    "        n = X.shape[0]\n",
    "        p = X.shape[1]\n",
    "        self.n_samples = n\n",
    "        self.n_features = p\n",
    "        \n",
    "        mu = self._sigmoid(self.coef_, X_)\n",
    "        self.deviance = -2*( ((X_.dot(self.coef_)).T).dot(y) + np.log(1 - mu).sum() )\n",
    "        self.residual_deviance = np.sqrt( -2*( (X_.dot(self.coef_))*(y) + np.log(1 - mu) ) )* np.sign(y - mu)\n",
    "        self.residual_pearson = (y - mu)/np.sqrt(mu*(1-mu))\n",
    "        self.pearson_chi2 = np.square(self.residual_pearson).sum()\n",
    "        \n",
    "        S = np.zeros((X_.shape[0], X_.shape[0]))\n",
    "        np.fill_diagonal(S, [i*(1-i) for i in mu])\n",
    "        covar = np.linalg.inv((X_.T).dot(S.dot(X_)))\n",
    "        \n",
    "        self.std_error = np.sqrt(np.diag( covar ))\n",
    "        self.z_values = self.coef_ / self.std_error\n",
    "        self.z_pvalues = [2*(1 - norm.cdf(abs(i),)) for i in self.z_values]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_ = np.append(np.ones((X.shape[0], 1)), X, axis=1)\n",
    "        result = np.array([1 if i >= .5 else 0 for i in self._sigmoid(self.coef_, X_)])\n",
    "        return result\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X_ = np.append(np.ones((X.shape[0], 1)), X, axis=1)\n",
    "        result = np.vstack((1. - self._sigmoid(self.coef_, X_), self._sigmoid(self.coef_, X_)))\n",
    "        return result.T\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        pred = self.predict(X,)\n",
    "        return np.array(pred==y, dtype=int).sum() / y.size\n",
    "    \n",
    "    def summary(self, feature_names = None, round_decimals=3, alpha=0.05):\n",
    "        '''res_min = self.residual.min()\n",
    "        res_max = self.residual.max()\n",
    "        res_1q = np.quantile(self.residual, .25)\n",
    "        res_med = np.median(self.residual)\n",
    "        res_3q = np.quantile(self.residual, .75)\n",
    "        res = pd.DataFrame(np.array([res_min, res_1q, res_med, res_3q, res_max]).reshape(1,-1), columns = ['Residuals: Min', '1Q', 'Median', '3Q', 'Max'])'''\n",
    "        \n",
    "        ci_lower = np.round(self.coef_ - self.std_error * norm.ppf(1-alpha/2, ), round_decimals)\n",
    "        ci_upper = np.round(self.coef_ + self.std_error * norm.ppf(1-alpha/2, ), round_decimals)\n",
    "        if feature_names is None:\n",
    "            feat_idx = ['x0(INTCP)'] + ['x{}'.format(i) for i in range(1, self.n_features+1)]\n",
    "            coef = pd.DataFrame(np.array([self.coef_, self.std_error, self.z_values, np.round(self.z_pvalues, round_decimals), ci_lower, ci_upper]).T, index = feat_idx, columns= \n",
    "                               ['coef.', 'std. error', 'z_value', 'Pr(>|z|)', '{}% LWR'.format(int(100*(1-alpha))), '{}% UPR'.format(int(100*(1-alpha)))])\n",
    "        else:\n",
    "            feat_idx = np.insert(feature_names, 0, '(INTCP)')\n",
    "            coef = pd.DataFrame(np.array([self.coef_, self.std_error, self.z_values, np.round(self.z_pvalues, round_decimals), ci_lower, ci_upper]).T, index = feat_idx, columns= \n",
    "                               ['coef.', 'std. error', 'z_value', 'Pr(>|z|)', '{}% LWR'.format(int(100*(1-alpha))), '{}% UPR'.format(int(100*(1-alpha)))])\n",
    "        result = 'No. Observations: {}\\nDF Residuals: {}\\nLog-likelihood: {}\\nDeviance: {}\\nPearson chi2: {}'.format(self.n_samples, self.n_features, self.log_likelihood, self.deviance, self.pearson_chi2)\n",
    "        if self.solver == 'irls':\n",
    "            sol = 'Solver: {}\\nNo. Iterations: {}'.format(self.solver.upper(), self.n_iter)\n",
    "            print(sol, result, coef, sep='\\n'+'='*70+'\\n')\n",
    "        else:\n",
    "            print(result, coef, sep='\\n'+'='*70+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y, feature_names,  = data['data'], 1 - data['target'], data['feature_names']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(X, columns = feature_names), pd.Series(y, name='label'), test_size = .2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## irls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  label   No. Observations:                  455\n",
      "Model:                            GLM   Df Residuals:                      448\n",
      "Model Family:                Binomial   Df Model:                            6\n",
      "Link Function:                  logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -89.286\n",
      "Date:                Mon, 30 Aug 2021   Deviance:                       178.57\n",
      "Time:                        21:12:38   Pearson chi2:                 1.48e+03\n",
      "No. Iterations:                     7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.2369      0.216     -5.728      0.000      -1.660      -0.814\n",
      "x1             0.2696      0.288      0.935      0.350      -0.296       0.835\n",
      "x2             0.2354      0.561      0.420      0.675      -0.864       1.335\n",
      "x3             0.2167      0.495      0.438      0.662      -0.754       1.187\n",
      "x4             4.4891      0.625      7.178      0.000       3.263       5.715\n",
      "x5             0.7051      0.281      2.511      0.012       0.155       1.255\n",
      "x6            -1.5538      0.443     -3.510      0.000      -2.422      -0.686\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "Xs = sm.add_constant(X_train[:, -6:])\n",
    "logit = sm.GLM(y_train, Xs, family=sm.families.Binomial(), )\n",
    "result = logit.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: IRLS\n",
      "No. Iterations: 7\n",
      "======================================================================\n",
      "No. Observations: 455\n",
      "DF Residuals: 6\n",
      "Log-likelihood: -89.28573873312577\n",
      "Deviance: 178.5714774662954\n",
      "Pearson chi2: 1484.4789667633481\n",
      "======================================================================\n",
      "              coef.  std. error   z_value  Pr(>|z|)  95% LWR  95% UPR\n",
      "x0(INTCP) -1.236908    0.215952 -5.727696     0.000   -1.660   -0.814\n",
      "x1         0.269614    0.288392  0.934889     0.350   -0.296    0.835\n",
      "x2         0.235429    0.561026  0.419640     0.675   -0.864    1.335\n",
      "x3         0.216709    0.495205  0.437615     0.662   -0.754    1.187\n",
      "x4         4.489082    0.625409  7.177829     0.000    3.263    5.715\n",
      "x5         0.705100    0.280765  2.511349     0.012    0.155    1.255\n",
      "x6        -1.553841    0.442719 -3.509767     0.000   -2.422   -0.686\n"
     ]
    }
   ],
   "source": [
    "lr = logistic_regression(solver = 'irls', penalty='none', C=1.)\n",
    "lr.fit(X_train[:, -6:], y_train)\n",
    "\n",
    "lr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
