{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Relationship between PCA and SVD](https://stats.stackexchange.com/a/134283)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large \\mathbf{X} = {\\begin{pmatrix} x_{1,1}&\\cdots&x_{1,p} \\\\ \\vdots & \\ddots &\\vdots \\\\ x_{n,1}&\\cdots&x_{n,p} \\end{pmatrix} }_{n\\times p} = {\\begin{pmatrix} X_1 & \\cdots&X_p \\end{pmatrix} }_{n\\times p}$ where $n$ is the number of samples and $p$ is the number of features.\n",
    "<br/><br/>\n",
    "$\\large \\mathrm{Cov}(X) = {\\begin{pmatrix} \\mathrm{cov}[X_1, X_1] & \\cdots & \\mathrm{cov}[X_1, X_p] \\\\ \\vdots & \\ddots &\\vdots \\\\ \\mathrm{cov}[X_p, X_1] & \\cdots & \\mathrm{cov}[X_p, X_p]\\end{pmatrix}}_{p\\times p} = {\\begin{pmatrix} \\mathrm{var}[X_1] & \\cdots & \\mathrm{cov}[X_1, X_p] \\\\ \\vdots & \\ddots &\\vdots \\\\ \\mathrm{cov}[X_p, X_1] & \\cdots & \\mathrm{var}[X_p]\\end{pmatrix}}_{p\\times p}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Large \\bullet \\textbf{ Gram-Schmidt process}$\n",
    "\n",
    "$\\large \\displaystyle \\mathrm{V} = \\begin{pmatrix} \\mathbf{v}_1 &\\mathbf{v}_2 & \\cdots & \\mathbf{v}_p \\end{pmatrix}$\n",
    ", where  $\\mathbf{v}_i$ for $i \\in \\{1,2,\\dots,p\\}$ are column vectors.\n",
    "\n",
    "$\\large \\begin{align}  \\mathbf{u}_1 &= \\mathbf{v}_1 \\\\ \\mathbf{u}_2 &= \\mathbf{v}_2 - \\frac{\\left\\langle \\mathbf{u}_1, \\mathbf{v}_2 \\right\\rangle}{\\left\\langle \\mathbf{u}_1, \\mathbf{u}_1 \\right\\rangle} \\mathbf{u}_1\\\\ \\mathbf{u}_3 &= \\mathbf{v}_3- \\frac{\\left\\langle \\mathbf{u}_2, \\mathbf{v}_3 \\right\\rangle}{\\left\\langle \\mathbf{u}_2, \\mathbf{u}_2\\right\\rangle} \\mathbf{u}_2 - \\frac{\\left\\langle \\mathbf{u}_1, \\mathbf{v}_3 \\right\\rangle}{\\left\\langle \\mathbf{u}_1, \\mathbf{u}_1\\right\\rangle} \\mathbf{u}_1\\\\ &\\ \\vdots \\nonumber \\\\\\mathbf{u}_p &= \\mathbf{v}_p - \\sum^{p-1}_{i=1} \\frac{\\langle \\mathbf{u}_i, \\mathbf{v}_p \\rangle}{\\left\\langle \\mathbf{u}_i, \\mathbf{u}_i\\right\\rangle} \\mathbf{u}_i\\\\\n",
    "\\end{align} $\n",
    "\n",
    "The orthogonal column vectors matrix is\n",
    "\n",
    "$\\large \\therefore \\mathrm{U} = \\begin{pmatrix} \\mathbf{u}_1 & \\mathbf{u}_2 &\\cdots & \\mathbf{u}_p \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gram_schmidt:\n",
    "    '''def __init__(self, X):\n",
    "        self.X = X.astype(float)'''\n",
    "        \n",
    "    def _proj(self, u, v):\n",
    "        return ((u.T).dot(v) / (u.T).dot(u))*u\n",
    "    \n",
    "    def fit_transform(self, X, col_vec = True, normal = True):\n",
    "        #X = X.astype(float)\n",
    "        if col_vec:\n",
    "            mat = X.copy()\n",
    "        else:\n",
    "            mat = (X.T).copy()\n",
    "        \n",
    "        N = mat.shape[1]\n",
    "        mat_orth = np.array([]).reshape(mat.shape[0], -1)\n",
    "        for n in range(N):\n",
    "            u = mat[:, n:n+1].copy()\n",
    "            if n ==0:\n",
    "                mat_orth = np.hstack((mat_orth,u))\n",
    "            else:\n",
    "                for i in range(n):\n",
    "                    u -= self._proj(mat_orth[:, i:i+1], mat[:, n:n+1])\n",
    "                mat_orth = np.hstack((mat_orth,u))\n",
    "        \n",
    "        if normal:\n",
    "            result = mat_orth / np.linalg.norm(mat_orth, axis=0)\n",
    "            if col_vec:\n",
    "                return result\n",
    "            else:\n",
    "                return result.T\n",
    "        else:\n",
    "            if col_vec:\n",
    "                return mat_orth\n",
    "            else:\n",
    "                return mat_orth.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd(data, reduced='thin'):\n",
    "    dim = data.shape[1]\n",
    "    rank = np.linalg.matrix_rank(data)\n",
    "    relu = np.vectorize(lambda x: x if x>=0 else .0)\n",
    "    \n",
    "    eval_u, evec_u = np.linalg.eig(data.dot(data.T))\n",
    "    eval_v, evec_v = np.linalg.eig(data.T.dot(data))\n",
    "    \n",
    "    gs = gram_schmidt()\n",
    "    #evec_u_gs = gs.fit_transform(np.real(evec_u))\n",
    "    #evec_v_gs = gs.fit_transform(np.real(evec_v))\n",
    "    \n",
    "    s = eval_v.copy()\n",
    "    s = np.sqrt(relu(s))\n",
    "    s1 = np.sort(s)[::-1]\n",
    "    if dim > rank:\n",
    "        s1[-(dim-rank):] = 0\n",
    "     \n",
    "    u_idx = np.sqrt(relu(np.real(eval_u))).argsort()[-dim:][::-1]\n",
    "    if reduced=='thin':\n",
    "        evec_u = evec_u[:, u_idx ]\n",
    "        S = np.eye(dim)\n",
    "        S *= s1     \n",
    "    else:        \n",
    "        evec_u = np.hstack((evec_u[:, u_idx ], np.delete(evec_u, u_idx, axis=1)))\n",
    "        S = np.zeros(data.shape)\n",
    "        np.fill_diagonal(S, s1)\n",
    "    \n",
    "    u = gs.fit_transform(np.real(evec_u))\n",
    "    \n",
    "    v_idx = np.sqrt(relu(np.real(eval_v))).argsort()[-dim:][::-1]\n",
    "    evec_v = evec_v[:, v_idx ]\n",
    "    v = gs.fit_transform(np.real(evec_v))\n",
    "    return u, S, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu, ss, vv = svd(data_x_std, reduced='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0242664 , -0.00028648, -0.02286707, -0.04226507],\n",
       "       [ 0.02300186, -0.03048532,  0.03569275,  0.01812984],\n",
       "       [ 0.04269872,  0.03298193, -0.03038933, -0.00589413],\n",
       "       ...,\n",
       "       [-0.02825438,  0.00468142, -0.00570868,  0.04847292],\n",
       "       [-0.03299276, -0.05398932, -0.01271873, -0.01253839],\n",
       "       [-0.01164199,  0.01096364, -0.00040428, -0.04319016]])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uu[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0242664 ,  0.00028648,  0.02286707,  0.04226507],\n",
       "       [ 0.02300186,  0.03048532, -0.03569275, -0.01812984],\n",
       "       [ 0.04269872, -0.03298193,  0.03038933,  0.00589413],\n",
       "       ...,\n",
       "       [-0.02825438, -0.00468142,  0.00570868, -0.04847292],\n",
       "       [-0.03299276,  0.05398932,  0.01271873,  0.01253839],\n",
       "       [-0.01164199, -0.01096364,  0.00040428,  0.04319016]])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.67673188,  0.181047  , -0.10787089, -0.70542173])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vv[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.67673188,  0.181047  , -0.10787089,  0.70542173])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.T[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(abs(uu[:,:20]), abs(u[:,:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(abs(vv), abs(v.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(ss.diagonal(), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5647267 , -0.47680363, -0.78627148, ...,  1.08572554,\n",
       "        -2.6671056 ,  1.15872028],\n",
       "       [ 1.44679163, -0.45103722,  1.08659197, ..., -1.28457032,\n",
       "        -1.04955323,  0.6106934 ],\n",
       "       [-3.19007586,  0.88998617,  2.55359432, ..., -0.84053839,\n",
       "         0.99574463, -1.13585373],\n",
       "       ...,\n",
       "       [-1.33127016, -0.52435115,  0.86350697, ...,  0.5527819 ,\n",
       "        -0.65783193, -1.74325353],\n",
       "       [ 2.15374311,  0.04029905, -0.20825025, ..., -1.44913037,\n",
       "         1.85544038, -0.89856518],\n",
       "       [ 0.2187607 ,  1.13683451, -0.81481309, ..., -0.04568927,\n",
       "        -0.16913704,  0.96884685]])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uu.dot(ss.dot(vv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(data_x_std, uu.dot(ss.dot(vv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.35587159, -0.22021195, -0.51007816,  0.74336135])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x_std[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.54566582,  1.39833053, -0.00319979, -0.66824935])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uu.dot(ss.dot(vv.T))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.35587159, -0.22021195, -0.51007816,  0.74336135],\n",
       "       [-0.60635073, -0.08883097,  0.07661929, -1.63845147],\n",
       "       [-1.15491588,  0.57826209, -1.2426252 ,  0.96683847],\n",
       "       ...,\n",
       "       [-0.39561355, -0.58737837,  1.50776079,  0.45752966],\n",
       "       [ 1.29201867, -1.62658271,  0.10409944, -0.52231705],\n",
       "       [ 1.09287156,  0.54004342, -0.50957456,  0.36172784]])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.dot(zzzz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss = np.zeros(data_x_std.shape)\n",
    "np.fill_diagonal(sss, s)\n",
    "zzzz = sss.dot(v)\n",
    "np.allclose(data_x_std, u.dot(zzzz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(ss.dot(vv.T), zzzz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.04093653,  11.85705953,   8.88837402, ...,  -8.96838802,\n",
       "          6.35307545,  -7.33362411],\n",
       "       [-14.63528048,   5.92302425,   9.16221672, ..., -10.35639044,\n",
       "        -15.71096592,  -0.37098284],\n",
       "       [-12.31918916,   0.30021872,   2.81180782, ...,  -0.25297427,\n",
       "          5.67919043,   3.33489377],\n",
       "       ...,\n",
       "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.04093653,  11.85705953,   8.88837402, ...,  -8.96838802,\n",
       "          6.35307545,  -7.33362411],\n",
       "       [-14.63528048,   5.92302425,   9.16221672, ..., -10.35639044,\n",
       "        -15.71096592,  -0.37098284],\n",
       "       [ 12.31918916,  -0.30021872,  -2.81180782, ...,   0.25297427,\n",
       "         -5.67919043,  -3.33489377],\n",
       "       ...,\n",
       "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        , ...,   0.        ,\n",
       "          0.        ,   0.        ]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.dot(vv.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_classification(n_features = 4, n_redundant=0,\n",
    "                           n_samples=10**3, weights=[0.9], random_state= 42, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data[0]\n",
    "data_y = data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large \\displaystyle \\mathbf{X}_{\\normalsize standardized} = \\begin{pmatrix} \\frac{X_1 -  \\mu_1}{\\sigma_1} & \\frac{X_2 -  \\mu_2}{\\sigma_2} & \\cdots &\\frac{X_p -  \\mu_p}{\\sigma_p}  \\end{pmatrix} $\n",
    ", where $\\mu_i$ and $\\sigma_i$ are mean and standard deviation of the vector $X_i$ for $i \\in \\{1,2,\\cdots,p\\}$.\n",
    "\n",
    "Therefore, the means of each column of matrix $\\mathbf{X}_{\\normalsize standardized}$ are all 0 and standard deviations are all 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_x_std = scaler.fit_transform(data_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large X_{n\\times p} = U\\; \\Sigma\\; V $\n",
    "\n",
    "$U_{n\\times n} =$ orthonormal eigenvectors of $XX^* $\n",
    "\n",
    "$\\Sigma_{n\\times p} =$  the square roots of the non-negative eigenvalues of both $X X^*$ and $X^* X $\n",
    "\n",
    "${V^*}_{p\\times p} =$ orthonormal eigenvectors of $X^*X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, v = np.linalg.svd(data_x_std, full_matrices=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(v.dot(v.T), np.eye(v.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999989"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.zeros(data_x_std.shape, float)\n",
    "np.fill_diagonal(S, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(np.dot(u, np.dot(S, v)), data_x_std )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large \\therefore X \\simeq U \\Sigma V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_u, evec_u = np.linalg.eig(data_x_std.dot(data_x_std.T))\n",
    "eval_v, evec_v = np.linalg.eig(data_x_std.T.dot(data_x_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = gram_schmidt()\n",
    "evec_u_gs = gs.fit_transform(np.real(evec_u))\n",
    "evec_v_gs = gs.fit_transform(evec_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(data_x_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36.62298228, 35.4665271 , 34.65973861, 33.65057709, 33.25522622,\n",
       "       33.02768341, 32.93607305, 32.56124304, 32.18629137, 31.71929746,\n",
       "       31.24794918, 31.07841663, 30.70064104, 30.31144614, 29.76964458,\n",
       "       29.24344091, 29.02919187, 27.96984113, 27.90012513, 27.10989188])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36.62298228, 35.4665271 , 34.65973861, 27.10989188, 27.90012513,\n",
       "       27.96984113, 29.02919187, 29.24344091, 29.76964458, 33.65057709,\n",
       "       30.31144614, 30.70064104, 31.07841663, 31.24794918, 31.71929746,\n",
       "       32.18629137, 33.25522622, 33.02768341, 32.93607305, 32.56124304])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(eval_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02627431, -0.06248842,  0.01506608,  0.00412621,  0.03052269,\n",
       "       -0.01413369, -0.01447024, -0.0337205 , -0.05524327,  0.0685282 ,\n",
       "       -0.03114748, -0.09625528, -0.02225258,  0.02172116, -0.01944328,\n",
       "       -0.00494595,  0.02787485, -0.00633242, -0.00782038,  0.02615544])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u[0,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4,  5],\n",
       "       [ 8,  9, 10],\n",
       "       [13, 14, 15],\n",
       "       [18, 19, 20],\n",
       "       [23, 24, 25]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zzz = np.arange(1,26).reshape(-1,5)\n",
    "np.delete(zzz, [0,1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 20)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evec_u_gs[:, ~(np.sqrt(np.vectorize(lambda x: x if x>=0 else .0)(np.real(eval_u))).argsort()[-20:][::-1]) ].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02627431, -0.06248842,  0.01506608,  0.00412621,  0.03052269,\n",
       "        0.01413369,  0.01447024,  0.0337205 , -0.05524327,  0.0685282 ,\n",
       "       -0.03114748,  0.09625528,  0.02225258, -0.02172116,  0.01944328,\n",
       "       -0.00494595,  0.02787485, -0.00633242, -0.00782038, -0.02615544])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evec_u_gs[:, np.sqrt(np.vectorize(lambda x: x if x>=0 else .0)(np.real(eval_u))).argsort()[-20:][::-1] ][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(abs(evec_u_gs[:, np.sqrt(np.vectorize(lambda x: x if x>=0 else .0)(np.real(eval_u))).argsort()[-20:][::-1] ][0]) , abs(u[0,:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 16, 15,\n",
       "       19, 18, 17], dtype=int64)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.vectorize(lambda x: x if x>=0 else .0)(np.real(eval_u))).argsort()[-20:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.66229823e+01, 3.54665271e+01, 3.46597386e+01, 3.36505771e+01,\n",
       "       3.32552262e+01, 3.30276834e+01, 3.29360731e+01, 3.25612430e+01,\n",
       "       3.21862914e+01, 3.17192975e+01, 3.12479492e+01, 3.10784166e+01,\n",
       "       3.07006410e+01, 3.03114461e+01, 2.97696446e+01, 2.90291919e+01,\n",
       "       2.92434409e+01, 2.71098919e+01, 2.79001251e+01, 2.79698411e+01,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 3.80870126e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "       3.44837393e-07, 3.03838628e-07, 3.03838628e-07, 2.01318457e-07,\n",
       "       2.01318457e-07, 3.12388595e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.53996837e-07, 2.49052843e-07,\n",
       "       2.49052843e-07, 8.20162314e-08, 8.20162314e-08, 2.21401845e-07,\n",
       "       2.21401845e-07, 0.00000000e+00, 0.00000000e+00, 1.96324965e-07,\n",
       "       1.96324965e-07, 0.00000000e+00, 0.00000000e+00, 2.37474021e-07,\n",
       "       2.37474021e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.77559362e-07, 1.77559362e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       2.25405462e-07, 2.25405462e-07, 2.14983865e-07, 2.14983865e-07,\n",
       "       1.94436792e-07, 1.94436792e-07, 2.29299555e-07, 2.29299555e-07,\n",
       "       2.26483594e-07, 2.26483594e-07, 2.17304851e-07, 2.17304851e-07,\n",
       "       2.24587127e-07, 2.15678751e-07, 2.15678751e-07, 2.18485062e-07,\n",
       "       2.18485062e-07, 2.20106351e-07, 2.20106351e-07, 2.06305841e-07,\n",
       "       2.06305841e-07, 2.13530979e-07, 2.13530979e-07, 2.12862500e-07,\n",
       "       2.12862500e-07, 2.15172065e-07, 2.13681782e-07, 2.10409138e-07,\n",
       "       2.10409138e-07, 0.00000000e+00, 0.00000000e+00, 4.02482535e-08,\n",
       "       4.02482535e-08, 1.33800812e-07, 1.33800812e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.78036772e-07,\n",
       "       1.78036772e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.98232410e-07, 1.98232410e-07,\n",
       "       2.06842937e-07, 2.06842937e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.04436565e-07, 2.04436565e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.96900181e-07,\n",
       "       1.96900181e-07, 1.97894658e-07, 1.97894658e-07, 2.07788326e-07,\n",
       "       2.07788326e-07, 2.03487966e-07, 2.03487966e-07, 2.02070874e-07,\n",
       "       2.02070874e-07, 2.04061296e-07, 2.04061296e-07, 2.03841959e-07,\n",
       "       2.03841959e-07, 1.89334460e-07, 1.89334460e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.96689823e-07,\n",
       "       1.96689823e-07, 1.99534373e-07, 1.99534373e-07, 1.77965456e-07,\n",
       "       1.77965456e-07, 9.86287398e-08, 9.86287398e-08, 1.82577319e-07,\n",
       "       1.82577319e-07, 1.56433077e-07, 1.56433077e-07, 1.89959597e-07,\n",
       "       1.89959597e-07, 1.93167412e-07, 1.93167412e-07, 1.89452061e-07,\n",
       "       1.89452061e-07, 1.83221545e-07, 1.83221545e-07, 1.95706260e-07,\n",
       "       1.95706260e-07, 1.95007873e-07, 1.95007873e-07, 1.94241548e-07,\n",
       "       2.65675015e-08, 2.65675015e-08, 1.89445251e-07, 1.89445251e-07,\n",
       "       1.90739438e-07, 1.90739438e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.26101391e-08,\n",
       "       6.26101391e-08, 0.00000000e+00, 0.00000000e+00, 1.21014791e-07,\n",
       "       1.21014791e-07, 1.65050102e-07, 1.65050102e-07, 1.74119887e-07,\n",
       "       1.74119887e-07, 1.89418835e-07, 1.60406171e-07, 1.60406171e-07,\n",
       "       1.66128839e-07, 1.66128839e-07, 1.82655533e-07, 1.82655533e-07,\n",
       "       1.89521344e-07, 1.89521344e-07, 1.78405317e-07, 1.78405317e-07,\n",
       "       1.72483710e-07, 1.72483710e-07, 1.87917552e-07, 1.87917552e-07,\n",
       "       1.83293638e-07, 1.83293638e-07, 1.76570349e-07, 1.76570349e-07,\n",
       "       4.36590277e-08, 4.36590277e-08, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.49968208e-07, 1.49968208e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.84665369e-07, 1.84665369e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.85634209e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.84578926e-07,\n",
       "       1.84578926e-07, 1.84576070e-07, 1.84576070e-07, 1.60947848e-07,\n",
       "       1.60947848e-07, 1.67574584e-07, 1.67574584e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.71797674e-07,\n",
       "       1.71797674e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.79267218e-07,\n",
       "       1.79267218e-07, 1.80931466e-07, 1.80931466e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.19592209e-07, 1.19592209e-07, 1.36221467e-07, 1.36221467e-07,\n",
       "       1.04527245e-07, 1.04527245e-07, 1.43058189e-07, 1.43058189e-07,\n",
       "       1.74044102e-07, 1.74044102e-07, 1.64305521e-07, 1.64305521e-07,\n",
       "       1.78827849e-07, 1.50567626e-07, 1.50567626e-07, 1.46725909e-07,\n",
       "       1.46725909e-07, 1.77743537e-07, 1.77743537e-07, 1.74250394e-07,\n",
       "       1.74250394e-07, 1.67567703e-07, 1.67567703e-07, 1.57850701e-07,\n",
       "       1.57850701e-07, 1.61021631e-07, 1.61021631e-07, 1.22108556e-07,\n",
       "       1.22108556e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.68876321e-07, 1.68876321e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 9.83227406e-08, 9.83227406e-08, 9.13096694e-08,\n",
       "       9.13096694e-08, 0.00000000e+00, 0.00000000e+00, 1.72312304e-07,\n",
       "       1.72312304e-07, 1.73880726e-07, 1.73880726e-07, 1.49395311e-07,\n",
       "       1.49395311e-07, 1.72288345e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.60990163e-07, 1.60990163e-07, 1.31888276e-07, 1.31888276e-07,\n",
       "       1.51782873e-07, 1.51782873e-07, 1.26208889e-07, 1.26208889e-07,\n",
       "       1.20726420e-07, 1.20726420e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.66966616e-07,\n",
       "       1.66966616e-07, 0.00000000e+00, 0.00000000e+00, 1.35922111e-07,\n",
       "       1.35922111e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.66768541e-07, 1.66768541e-07, 1.61668312e-08,\n",
       "       1.61668312e-08, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.59443666e-07,\n",
       "       1.59443666e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.42464730e-07, 1.42464730e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.61383436e-07, 1.61383436e-07, 1.65186663e-07,\n",
       "       1.65186663e-07, 1.62994435e-07, 1.62994435e-07, 1.65295501e-07,\n",
       "       1.65295501e-07, 9.63202408e-08, 9.63202408e-08, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.52086570e-07, 1.52086570e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.56361988e-07,\n",
       "       1.56361988e-07, 1.36951266e-07, 1.36951266e-07, 8.33421112e-08,\n",
       "       8.33421112e-08, 5.84707283e-08, 5.84707283e-08, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.49501815e-07,\n",
       "       1.49501815e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.22305725e-08,\n",
       "       5.22305725e-08, 1.02856930e-07, 1.02856930e-07, 1.19193874e-07,\n",
       "       1.19193874e-07, 1.29501312e-07, 1.29501312e-07, 1.47655658e-07,\n",
       "       1.47655658e-07, 1.40379720e-07, 1.40379720e-07, 1.60508453e-07,\n",
       "       1.60508453e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 6.56526638e-08, 6.56526638e-08, 1.20818164e-07,\n",
       "       1.20818164e-07, 1.58571944e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.54935191e-07, 1.54935191e-07, 1.53066084e-07, 1.53066084e-07,\n",
       "       1.46801251e-07, 1.46801251e-07, 1.25839231e-07, 1.25839231e-07,\n",
       "       1.56904871e-07, 1.56904871e-07, 1.04229582e-07, 1.04229582e-07,\n",
       "       1.36347159e-07, 1.36347159e-07, 1.34221453e-07, 1.34221453e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 2.69267850e-08, 2.69267850e-08, 7.35004570e-08,\n",
       "       7.35004570e-08, 0.00000000e+00, 0.00000000e+00, 1.07997087e-07,\n",
       "       1.07997087e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.53540407e-07, 1.53540407e-07, 1.50643862e-07,\n",
       "       1.50643862e-07, 1.43559139e-07, 1.43559139e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 8.37796901e-08, 8.37796901e-08, 1.37295638e-07,\n",
       "       1.37295638e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.91175453e-08,\n",
       "       8.91175453e-08, 0.00000000e+00, 0.00000000e+00, 1.12166063e-07,\n",
       "       1.12166063e-07, 0.00000000e+00, 1.25220705e-07, 1.25220705e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 9.93978442e-08, 9.93978442e-08,\n",
       "       1.49534064e-07, 1.49534064e-07, 1.49447787e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.31574712e-07, 1.31574712e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.35444462e-07, 1.35444462e-07, 1.43670179e-07,\n",
       "       1.43670179e-07, 1.46811527e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.40583160e-07, 1.40583160e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.39565258e-07, 1.39565258e-07, 1.15164461e-07, 1.15164461e-07,\n",
       "       1.32714131e-07, 1.32714131e-07, 1.45859296e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.72713781e-08,\n",
       "       4.72713781e-08, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.45162246e-08,\n",
       "       8.45162246e-08, 9.75333758e-08, 9.75333758e-08, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.48488668e-08,\n",
       "       7.48488668e-08, 0.00000000e+00, 0.00000000e+00, 1.12617186e-07,\n",
       "       1.12617186e-07, 6.84116151e-08, 6.84116151e-08, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.39377769e-07, 1.39377769e-07,\n",
       "       1.23786363e-07, 1.23786363e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.39678347e-07, 1.39678347e-07, 9.57037325e-08, 9.57037325e-08,\n",
       "       1.07566679e-07, 1.07566679e-07, 1.18724288e-07, 1.18724288e-07,\n",
       "       1.31147792e-07, 1.31147792e-07, 3.61391342e-08, 3.61391342e-08,\n",
       "       1.25350561e-07, 1.25350561e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.13696873e-07, 1.13696873e-07, 1.37441537e-07,\n",
       "       1.37441537e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 5.96696658e-08, 5.96696658e-08,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.12411015e-07, 1.12411015e-07,\n",
       "       1.34813380e-07, 1.34813380e-07, 8.31912766e-08, 8.31912766e-08,\n",
       "       1.23240870e-07, 1.23240870e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.31158302e-07, 1.31158302e-07,\n",
       "       9.51472989e-08, 9.51472989e-08, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.26752195e-07, 1.26752195e-07, 1.32031875e-07, 1.32031875e-07,\n",
       "       1.30871896e-07, 1.16822820e-07, 1.16822820e-07, 4.23329617e-08,\n",
       "       4.23329617e-08, 2.70683319e-09, 2.70683319e-09, 8.75919120e-08,\n",
       "       8.75919120e-08, 0.00000000e+00, 0.00000000e+00, 6.71944237e-08,\n",
       "       6.71944237e-08, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.04174539e-07, 1.04174539e-07, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.23774419e-07, 1.23774419e-07, 1.16535461e-07,\n",
       "       1.16535461e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.18133590e-07,\n",
       "       1.18133590e-07, 0.00000000e+00, 0.00000000e+00, 1.19625428e-07,\n",
       "       1.19625428e-07, 0.00000000e+00, 0.00000000e+00, 4.42893321e-08,\n",
       "       4.42893321e-08, 5.94711456e-08, 5.94711456e-08, 7.21194979e-08,\n",
       "       7.21194979e-08, 8.34686402e-08, 8.34686402e-08, 9.65716826e-08,\n",
       "       9.65716826e-08, 1.04744143e-07, 1.04744143e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.12191010e-07,\n",
       "       1.12191010e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.08708536e-07,\n",
       "       1.08708536e-07, 1.17721998e-07, 3.85447544e-08, 3.85447544e-08,\n",
       "       1.04290392e-07, 1.04290392e-07, 8.79431312e-08, 8.79431312e-08,\n",
       "       0.00000000e+00, 0.00000000e+00, 8.28331530e-08, 8.28331530e-08,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.16472081e-07, 1.16472081e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 6.97977583e-08, 6.97977583e-08,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.01432093e-07,\n",
       "       1.01432093e-07, 8.20808514e-08, 8.20808514e-08, 1.04335154e-07,\n",
       "       1.04335154e-07, 9.28248872e-08, 9.28248872e-08, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.07313817e-07, 1.07313817e-07, 3.17065317e-08,\n",
       "       3.17065317e-08, 7.05625115e-08, 7.05625115e-08, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.03580686e-07, 1.03580686e-07,\n",
       "       3.92235712e-08, 3.92235712e-08, 1.04461251e-07, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 8.74058498e-08, 8.74058498e-08, 9.16773559e-08,\n",
       "       9.16773559e-08, 0.00000000e+00, 9.58186805e-08, 9.58186805e-08,\n",
       "       7.20317886e-08, 7.20317886e-08, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 4.94302813e-08, 4.94302813e-08,\n",
       "       0.00000000e+00, 0.00000000e+00, 9.42365989e-08, 9.42365989e-08,\n",
       "       7.57963743e-08, 7.57963743e-08, 0.00000000e+00, 0.00000000e+00,\n",
       "       8.90075779e-08, 8.90075779e-08, 9.23499053e-08, 2.49694817e-08,\n",
       "       2.49694817e-08, 0.00000000e+00, 0.00000000e+00, 6.75822028e-08,\n",
       "       6.75822028e-08, 7.94122116e-08, 7.94122116e-08, 4.81912791e-08,\n",
       "       4.81912791e-08, 0.00000000e+00, 8.64803705e-08, 8.46964248e-08,\n",
       "       8.46964248e-08, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       6.77031636e-08, 6.77031636e-08, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       3.58805683e-08, 3.58805683e-08, 8.07118683e-08, 8.07118683e-08,\n",
       "       5.62608189e-08, 5.62608189e-08, 7.59067785e-08, 7.59067785e-08,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 7.63478519e-08, 4.02333740e-08,\n",
       "       4.02333740e-08, 0.00000000e+00, 0.00000000e+00, 6.76614909e-08,\n",
       "       6.76614909e-08, 0.00000000e+00, 0.00000000e+00, 5.57117927e-08,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 5.84964314e-08, 5.84964314e-08,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.89460127e-08, 2.89460127e-08,\n",
       "       4.55869088e-08, 4.55869088e-08, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 3.18259486e-08, 3.18259486e-08, 0.00000000e+00])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.vectorize(lambda x: x if x>=0 else .0)(np.real(eval_u)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-157-e117c599922b>:1: RuntimeWarning: invalid value encountered in sqrt\n",
      "  np.isin(np.sqrt(np.real(eval_u)), np.sqrt(eval_v))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isin(np.sqrt(np.real(eval_u)), np.sqrt(eval_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 18,  8,  9, 13, 15, 16, 17, 14, 12, 11, 10,  7,  6,  5,  4,  3,\n",
       "        2,  1,  0], dtype=int64)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_v[[eval_v.argsort()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27.10989188, 27.90012513, 27.96984113, 29.02919187, 29.24344091,\n",
       "       29.76964458, 30.31144614, 30.70064104, 31.07841663, 31.24794918,\n",
       "       31.71929746, 32.18629137, 32.56124304, 32.93607305, 33.02768341,\n",
       "       33.25522622, 33.65057709, 34.65973861, 35.4665271 , 36.62298228])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.nan_to_num(np.sqrt(np.real(eval_v)), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-119-a57b782d93bb>:1: RuntimeWarning: invalid value encountered in sqrt\n",
      "  np.sort(np.nan_to_num(np.sqrt(np.real(eval_u)), 0))[::-1][:20]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([36.62298228, 35.4665271 , 34.65973861, 33.65057709, 33.25522622,\n",
       "       33.02768341, 32.93607305, 32.56124304, 32.18629137, 31.71929746,\n",
       "       31.24794918, 31.07841663, 30.70064104, 30.31144614, 29.76964458,\n",
       "       29.24344091, 29.02919187, 27.96984113, 27.90012513, 27.10989188])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.nan_to_num(np.sqrt(np.real(eval_u)), 0))[::-1][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(np.zeros((6,4)), np.arange(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  4.],\n",
       "       [10., 12., 14., 16.],\n",
       "       [27., 30., 33., 36.],\n",
       "       [52., 56., 60., 64.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = np.zeros((6,4))\n",
    "np.fill_diagonal(xx, np.arange(1,5))\n",
    "xx.dot(np.arange(1,17).reshape(-1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8],\n",
       "       [ 9, 10, 11, 12],\n",
       "       [13, 14, 15, 16]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1,17).reshape(-1,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01828462,  0.04724048, -0.02791569, -0.00476045, -0.01081699,\n",
       "       -0.01415586,  0.04619612, -0.03305375,  0.01476144, -0.05566156,\n",
       "       -0.02595789, -0.00378986, -0.0323959 ,  0.00981624,  0.00089818])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u[0,:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01828462,  0.04724048, -0.02791569, -0.00476045,  0.01081699,\n",
       "        0.01415586, -0.04619612, -0.03305375,  0.02595789,  0.02238961,\n",
       "       -0.01663035, -0.0323959 , -0.00089818, -0.00260253, -0.00981624])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.real(evec_u[:,np.sqrt(abs(np.real(eval_v))).argsort()[::-1]][0,:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(evec_v_gs.dot(evec_v_gs.T), np.eye(evec_v_gs.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 18,  4,  5,  6,  7,  8, 10, 11, 12, 13, 17, 16, 15, 14,  9,  3,\n",
       "        2,  1,  0], dtype=int64)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(abs(np.real(eval_v))).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.54205355e+01, 3.45049635e+01, 3.43763398e+01, 3.39458464e+01,\n",
       "       3.37255154e+01, 3.32130138e+01, 3.28376444e+01, 3.25646897e+01,\n",
       "       3.17946166e+01, 3.17083444e+01, 3.08858574e+01, 3.05148789e+01,\n",
       "       2.99609330e+01, 2.98545964e+01, 2.95726288e+01, 2.92951048e+01,\n",
       "       2.84758091e+01, 2.81185613e+01, 1.39203880e-14, 1.16748491e-14])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.54205355e+01, 3.45049635e+01, 3.43763398e+01, 3.39458464e+01,\n",
       "       3.37255154e+01, 3.32130138e+01, 3.28376444e+01, 3.25646897e+01,\n",
       "       3.17946166e+01, 3.17083444e+01, 3.08858574e+01, 3.05148789e+01,\n",
       "       2.99609330e+01, 2.98545964e+01, 2.95726288e+01, 2.92951048e+01,\n",
       "       2.84758091e+01, 2.81185613e+01, 4.60001772e-07, 3.13500387e-07])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.sqrt(abs(eval_v)))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-eeac0a74da89>:1: RuntimeWarning: invalid value encountered in sqrt\n",
      "  np.sort(np.nan_to_num(np.sqrt(eval_v),0))[::-1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.54205355e+01, 3.45049635e+01, 3.43763398e+01, 3.39458464e+01,\n",
       "       3.37255154e+01, 3.32130138e+01, 3.28376444e+01, 3.25646897e+01,\n",
       "       3.17946166e+01, 3.17083444e+01, 3.08858574e+01, 3.05148789e+01,\n",
       "       2.99609330e+01, 2.98545964e+01, 2.95726288e+01, 2.92951048e+01,\n",
       "       2.84758091e+01, 2.81185613e+01, 4.60001772e-07, 0.00000000e+00])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.nan_to_num(np.sqrt(eval_v),0))[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.09124406e-02,  3.53755625e-02, -2.23088454e-01,  3.08145422e-02,\n",
       "        1.40965890e-01,  4.36320529e-01,  2.93179868e-01,  1.15110843e-01,\n",
       "       -8.89513509e-02, -5.88986414e-01,  1.53103165e-01, -1.56757561e-01,\n",
       "       -1.65388383e-01, -6.38952559e-02,  1.96094406e-01, -2.00332607e-01,\n",
       "       -2.52898496e-01, -2.48292121e-01,  1.97553277e-16, -1.00982859e-16])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.T[3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.09124406e-02,  3.53755625e-02,  2.23088454e-01, -3.08145422e-02,\n",
       "        1.40965890e-01, -4.36320529e-01, -2.93179868e-01,  1.15110843e-01,\n",
       "       -8.89513509e-02, -5.88986414e-01,  1.53103165e-01,  1.56757561e-01,\n",
       "       -1.65388383e-01, -6.38952559e-02, -1.96094406e-01, -2.00332607e-01,\n",
       "       -2.52898496e-01,  2.48292121e-01,  2.19644772e-17, -4.36892929e-16])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.real(evec_v_gs[:,np.sqrt(abs(np.real(eval_v))).argsort()[::-1]])[3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = gram_schmidt()\n",
    "ev_orth = np.real(gs.orthonormal(ev, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.29222837e-02,  5.05722912e-01, -6.56554623e-02,  1.11001843e-01,\n",
       "       -2.38002695e-01,  8.32706762e-02,  1.72357613e-01,  8.64398786e-02,\n",
       "       -1.29605480e-02,  4.39800060e-01, -3.06539027e-01,  3.62347473e-02,\n",
       "       -2.50551049e-03, -1.59530740e-02, -2.07104101e-01,  2.14519904e-01,\n",
       "        4.72252971e-01, -1.58942830e-01,  5.97211875e-17, -3.02034327e-17])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.T[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.29222837e-02, -5.05722912e-01,  6.56554623e-02,  1.11001843e-01,\n",
       "        1.58942830e-01,  4.72252971e-01,  2.14519904e-01, -2.07104101e-01,\n",
       "        1.59530740e-02, -2.38002695e-01, -2.50551049e-03,  3.62347473e-02,\n",
       "        3.06539027e-01,  4.39800060e-01, -8.32706762e-02, -1.72357613e-01,\n",
       "       -8.64398786e-02,  1.29605480e-02,  1.56755213e-17, -8.81978737e-18])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev_orth[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(ev_orth[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(v.T[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False],\n",
       "       [False, False, False]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(v[:,:3],np.real(gs.orthonormal(ev, )[:,:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02292228,  0.50572291, -0.06565546],\n",
       "       [ 0.55962697,  0.05425466, -0.04748907],\n",
       "       [-0.0203438 , -0.01816242, -0.51729607],\n",
       "       [ 0.00109865, -0.1577597 , -0.07062832],\n",
       "       [-0.04118024, -0.25275819, -0.01802699],\n",
       "       [-0.47676204,  0.15049368, -0.05232398],\n",
       "       [ 0.0125351 ,  0.09318769,  0.45878404],\n",
       "       [ 0.01736969, -0.20223319, -0.02511544],\n",
       "       [ 0.03330077,  0.05702416, -0.17681541],\n",
       "       [-0.00782674, -0.28581579,  0.09669366],\n",
       "       [-0.01586192,  0.22138756, -0.18911348],\n",
       "       [ 0.01047088, -0.24002708, -0.27383818],\n",
       "       [ 0.02324671,  0.06861466, -0.03325629],\n",
       "       [ 0.05600357,  0.1658956 ,  0.48019901],\n",
       "       [-0.37526174, -0.21968459,  0.11830003],\n",
       "       [ 0.00791182, -0.35257137, -0.07828296],\n",
       "       [-0.02624688,  0.30492018,  0.00310865],\n",
       "       [-0.01452093,  0.1160483 , -0.10764729],\n",
       "       [ 0.55590289, -0.05176735,  0.00266235],\n",
       "       [-0.02001138,  0.27290482, -0.30312492]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.T[:,:3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02292228, -0.50572291,  0.06565546],\n",
       "       [ 0.55962697, -0.05425466,  0.04748907],\n",
       "       [-0.0203438 ,  0.01816242,  0.51729607],\n",
       "       [ 0.00109865,  0.1577597 ,  0.07062832],\n",
       "       [-0.04118024,  0.25275819,  0.01802699],\n",
       "       [-0.47676204, -0.15049368,  0.05232398],\n",
       "       [ 0.0125351 , -0.09318769, -0.45878404],\n",
       "       [ 0.01736969,  0.20223319,  0.02511544],\n",
       "       [ 0.03330077, -0.05702416,  0.17681541],\n",
       "       [-0.00782674,  0.28581579, -0.09669366],\n",
       "       [-0.01586192, -0.22138756,  0.18911348],\n",
       "       [ 0.01047088,  0.24002708,  0.27383818],\n",
       "       [ 0.02324671, -0.06861466,  0.03325629],\n",
       "       [ 0.05600357, -0.1658956 , -0.48019901],\n",
       "       [-0.37526174,  0.21968459, -0.11830003],\n",
       "       [ 0.00791182,  0.35257137,  0.07828296],\n",
       "       [-0.02624688, -0.30492018, -0.00310865],\n",
       "       [-0.01452093, -0.1160483 ,  0.10764729],\n",
       "       [ 0.55590289,  0.05176735, -0.00266235],\n",
       "       [-0.02001138, -0.27290482,  0.30312492]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev_orth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = gram_schmidt()\n",
    "ev_orth = np.real(gs.orthonormal(ev, )[:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.58069699e-02,  3.01698041e-02, -3.92649977e-03, ...,\n",
       "         2.50448298e-02, -3.82197662e-02, -3.66543863e-02],\n",
       "       [-5.22878445e-03, -3.06603742e-02,  1.55813512e-02, ...,\n",
       "        -2.54367666e-02, -4.40285614e-02, -1.38019509e-02],\n",
       "       [ 4.67882864e-03, -7.81796912e-02, -1.31807645e-02, ...,\n",
       "        -3.06775784e-02,  3.01705551e-02, -1.05746981e-02],\n",
       "       ...,\n",
       "       [-2.34054071e-02, -6.97085261e-02,  8.71660084e-03, ...,\n",
       "         9.75102822e-01,  7.05642576e-04,  2.80920160e-03],\n",
       "       [-1.42460634e-02, -7.98736725e-03, -2.16604159e-02, ...,\n",
       "         1.85549046e-03,  9.82551168e-01,  6.20014067e-03],\n",
       "       [-1.94011010e-02,  2.70296071e-02,  4.82344894e-03, ...,\n",
       "         6.53096767e-04,  5.39052629e-03,  9.84550389e-01]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov= np.cov(X_train_sc - X_train_sc.mean(axis=0), rowvar=False)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 20)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.dot(np.diag(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.77774354, -0.58563607],\n",
       "       [ 0.2612659 ,  0.59186165],\n",
       "       [-0.23103433,  2.09704588],\n",
       "       ...,\n",
       "       [ 1.16470754,  2.06088412],\n",
       "       [ 0.70823629,  0.47223255],\n",
       "       [ 0.96628558, -1.09295898]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xpca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.78141977, -0.94647922],\n",
       "       [ 0.26013539,  0.96186926],\n",
       "       [-0.23277473,  2.45263287],\n",
       "       ...,\n",
       "       [ 1.16443405,  2.18687769],\n",
       "       [ 0.70875081,  0.2505776 ],\n",
       "       [ 0.96521724, -0.84796578]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train_sc - X_train_sc.mean(axis=0)).dot(pca.components_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(xpca, X_train_sc.dot(pca.components_.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999993"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.0668676 , 0.93813866])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.0668676 , 0.93813866])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train_sc - X_train_sc.mean(axis=0)).dot(pca.components_.T).var(axis=0, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(v[0], eigenvectors.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5057229118627715"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvectors[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(abs(v), abs(eigenvectors.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(v.T.dot(v), np.eye(v.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True, False],\n",
       "       [ True,  True, False,  True]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(eigenvectors.T.dot(eigenvectors), np.eye(eigenvectors.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_idx = 0\n",
    "cosine_similarity(v[comp_idx:comp_idx+1,:], eigenvectors[:,comp_idx].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7763568394002505e-15"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((u.T).dot(u) - np.eye(800)).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose((u.T).dot(u) , np.eye(u.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose((v.T).dot(v) , np.eye(v.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., -0., -0., ...,  0.,  0.,  0.],\n",
       "       [-0., -0., -0., ...,  0.,  0.,  0.],\n",
       "       [-0., -0., -0., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  0., -0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., -0.,  0., -0.],\n",
       "       [ 0.,  0.,  0., ...,  0., -0., -0.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round((u.T).dot(u) - np.eye(800), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., -0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0., -0.,  0.,  1.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round((v.T).dot(v), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.01230942,  0.06288618, -0.03379583, -0.08403019],\n",
       "        [ 0.06288618,  1.14011871,  0.01014754, -0.09029393],\n",
       "        [-0.03379583,  0.01014754,  0.90831919, -0.11137876],\n",
       "        [-0.08403019, -0.09029393, -0.11137876,  0.93925268]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvectors.dot( np.matrix(eigenvectors).H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  1.  , -0.  , -0.  ],\n",
       "       [ 0.  , -0.  ,  1.  ,  0.22],\n",
       "       [ 0.  , -0.  ,  0.22,  1.  ]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round((eigenvectors.T).dot(eigenvectors),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.06686760e+00, 9.38138656e-01, 1.54891299e-31, 4.74019816e-32])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(s)/(X_train_sc.shape[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.06686760e+00, 9.38138656e-01, 1.54891299e-31, 4.74019816e-32])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(s)/(X_train_sc.shape[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov= np.cov(X_train_sc - X_train_sc.mean(axis=0), rowvar=False)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(np.round(eigenvectors.T.dot(eigenvectors),2),np.eye(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999997"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(pca.components_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.06686760e+00, 9.38138656e-01, 9.63907292e-17, 2.74949812e-16])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.0668676 , 0.93813866])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7657585, 0.2342415])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37537327, -0.56343987,  0.47853489, -0.55913753],\n",
       "       [-0.77887225,  0.17161566,  0.5645045 , -0.21269872]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37537327, -0.56343987,  0.47853489, -0.55913753],\n",
       "       [-0.77887225,  0.17161566,  0.5645045 , -0.21269872]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(eigenvectors[:, :2].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23675929,  0.79205581],\n",
       "       [ 0.96430644, -1.33873515],\n",
       "       [-2.64001914,  0.06398657],\n",
       "       ...,\n",
       "       [ 1.64837173, -0.88211564],\n",
       "       [-2.08038828,  0.35941666],\n",
       "       [ 0.01904595, -0.24080798]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xpca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23675929,  0.79205581],\n",
       "       [ 0.96430644, -1.33873515],\n",
       "       [-2.64001914,  0.06398657],\n",
       "       ...,\n",
       "       [ 1.64837173, -0.88211564],\n",
       "       [-2.08038828,  0.35941666],\n",
       "       [ 0.01904595, -0.24080798]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train_sc - X_train_sc.mean(axis=0)).dot(pca.components_.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st and 2nd component vectors are orthonormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round((eigenvectors[:, :2].T).dot(eigenvectors[:, :2]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
